# -*- coding: utf-8 -*-
"""Proyek Akhir: Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dwzXZOeu1nQE1ov2U4cNze0TCTg6NPCO

# WSDM - KKBox's Music Recommendation
By Daffa Muhamad Azhar
"""

# Menyambungkan ke Google Drive
from google.colab import drive
drive.mount('/content/drive')

root = '/content/drive/MyDrive/Colab Notebooks/Dicoding/Dataset/Sistem Rekomendasi Musik/'

"""## Import Data"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# tabel setting
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

train = pd.read_csv(root + 'train.csv')
member = pd.read_csv(root + 'members.csv')
song = pd.read_csv(root + 'songs.csv')

train = train.sample(frac=0.45)

"""## Exploratory Data Analysis

### Train Data
"""

train.head()

train.info()

train.shape

"""Cek missing data"""

# Cek Missing Data
total_missing = train.isnull().sum().sort_values(ascending=False)
percent_1 = train.isnull().sum()/train.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_2], axis=1, keys=['Total Missing', '%'])
missing_data = missing_data.reset_index().rename(columns={'index': 'Column'})
missing_data

"""Cek perbandingan target"""

fig = px.pie(train, names='target',)
fig.update_layout(title='Persentase dari target')
fig.show()

"""Hubungan `Source Type` dengan `Target`"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (10,10))
plot = sns.countplot(data=train, y='source_type', hue="target", ax=ax)

"""Hubungan `Source System Tab` dengan `Target`"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (10,10))
plot = sns.countplot(data=train, y='source_system_tab', hue="target", ax=ax)

"""Hubungan `Source Screen Name` dengan `Target`"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (10,10))
plot = sns.countplot(data=train, y='source_screen_name', hue="target", ax=ax)

"""### Members Data"""

member.head()

member.info()

"""Dapat dilihat bahwa tipe data registration dan expiration masih berupa integer sehingga harus diubah terlebih dahulu"""

member['registration_init_time']=pd.to_datetime(member.registration_init_time, format='%Y%m%d')
member['expiration_date']=pd.to_datetime(member.expiration_date, format='%Y%m%d')

member.describe()

# Cek Missing Data
total_missing = member.isnull().sum().sort_values(ascending=False)
percent_1 = member.isnull().sum()/member.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_2], axis=1, keys=['Total Missing', '%'])
missing_data = missing_data.reset_index().rename(columns={'index': 'Column'})
missing_data

"""Persebaran Umur pada Member"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (30,5))
plot = sns.countplot(data=member, x='bd', ax=ax)

"""Terdapat Outlier pada kolom `bd`.

Persebaran Gender pada Member
"""

fig = px.pie(member, names='gender',)
fig.update_layout(title='Persentase dari Gender')
fig.show()

"""Terdapat `Null` gender yang diasumsikan bahwa mereka memilih untuk tidak memiliki jenis kelamin.

Persebaran kota pada member
"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (15,5))
plot = sns.countplot(data=member, x='city', ax=ax)

"""Persebaran `registered via` pada Member"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (15,5))
plot = sns.countplot(data=member, x='registered_via', ax=ax)

"""Menghitung total pendaftar baik harian maupun bulanan"""

timestamp = member.groupby(['registration_init_time'], as_index=False)['msno'].count().sort_values('registration_init_time', ascending=True).rename(columns={'msno': 'Jumlah Pendaftar'})

timestamp.head()

fig, ax = plt.subplots(1, 1, figsize = (20,5))

sns.lineplot(x="registration_init_time", y='Jumlah Pendaftar', data=timestamp, ax=ax)
ax.title.set_text('Pendaftar Setiap Hari')

timestamp_monthly = timestamp.groupby(pd.Grouper(key='registration_init_time', freq='M')).agg({'Jumlah Pendaftar':'sum'}).reset_index()

fig, ax = plt.subplots(1, 1, figsize = (20,5))

sns.lineplot(x="registration_init_time", y='Jumlah Pendaftar', data=timestamp_monthly, ax=ax)
ax.title.set_text('Pendaftar Setiap Bulan')

"""### Songs Data"""

song.head()

song.info()

song.describe()

"""Cek Missing Data"""

# Cek Missing Data
total_missing = song.isnull().sum().sort_values(ascending=False)
percent_1 = song.isnull().sum()/song.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_2], axis=1, keys=['Total Missing', '%'])
missing_data = missing_data.reset_index().rename(columns={'index': 'Column'})
missing_data

"""Genre yang paling banyak"""

genre = song.groupby(['genre_ids'], as_index=False)['song_id'].count().sort_values('song_id', ascending=False).rename(columns={'song_id': 'total'})

fig, ax = plt.subplots(1, 1, figsize = (15,10))

sns.barplot(x="total", y='genre_ids', data=genre.head(10), ax=ax)
ax.title.set_text('TOP GENRE')

del genre

"""Bahasa yang paling banyak"""

y = 1
x = 1
fig, ax = plt.subplots(y, x, figsize = (15,5))
plot = sns.countplot(data=song, x='language', ax=ax)

"""## Data Preparation

Merge Dataset
"""

train = pd.merge(train, song, on='song_id', how='left')

train = pd.merge(train, member, on='msno', how='left')

del song
del member

train.info()

print("Total Data Pada Dataset :", train.shape[0])
print("Total Fitur Pada Dataset :", train.shape[1])

# Cek Missing Data
total_missing = train.isnull().sum().sort_values(ascending=False)
percent_1 = train.isnull().sum()/train.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_2], axis=1, keys=['Total Missing', '%'])
missing_data = missing_data.reset_index().rename(columns={'index': 'Column'})
missing_data

"""Mengisi `NULL` value pada kolom object dengan `UNKNOWN` dan mengisi nilai 0 untuk tipe data numerikal karena data tidak dapat dipastikan atau dilakukan agregasi."""

for col in train.select_dtypes(include=['object']).columns:
    train[col] = train[col].fillna('UNKNOWN')

train = train.fillna(value=0)

# Cek Missing Data
total_missing = train.isnull().sum().sort_values(ascending=False)
percent_1 = train.isnull().sum()/train.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_2], axis=1, keys=['Total Missing', '%'])
missing_data = missing_data.reset_index().rename(columns={'index': 'Column'})
missing_data

train.head()

train['registration_init_time_year'] = train['registration_init_time'].dt.year
train['registration_init_time_month'] = train['registration_init_time'].dt.month
train['registration_init_time_day'] = train['registration_init_time'].dt.day

train['expiration_date_year'] = train['expiration_date'].dt.year
train['expiration_date_month'] = train['expiration_date'].dt.month
train['expiration_date_day'] = train['expiration_date'].dt.day

train = train.drop(columns=['registration_init_time','expiration_date'])

# Object data to category
for col in train.select_dtypes(include=['object']).columns:
    train[col] = train[col].astype('category')
    
# Encoding categorical features
for col in train.select_dtypes(include=['category']).columns:
    train[col] = train[col].cat.codes

train.shape

"""## Modeling"""

# import libraries
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingRegressor
import lightgbm as lgb
import xgboost as xgb

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, classification_report, roc_auc_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

"""### Splitting Dataset"""

# Drop Target dan ID
X = train.drop(['target'], axis=1)
Y = train.target

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)

print('Shape X_train : ', X_train.shape)
print('Shape X_test : ', X_test.shape)
print('Shape y_train : ', y_train.shape)
print('Shape y_test : ', y_test.shape)

"""### Pelatihan

#### XGBoost
"""

params = {
    'objective': 'binary:logistic',
    'eval_metric': 'auc',
    'max_depth': 15,
    'learning_rate': 0.001,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'gamma': 1,
    'min_child_weight': 1,
    'reg_alpha': 0,
    'reg_lambda': 1
}

xgb_model = xgb.XGBClassifier(**params)

xgb_model.fit(X_train, y_train)

"""#### LightGBM"""

params = {
    'objective': 'binary',
    'boosting': 'gbdt',
    'learning_rate': 0.001 ,
    'verbose': 0,
    'num_leaves': 2**8,
    'bagging_fraction': 0.95,
    'bagging_freq': 1,
    'bagging_seed': 1,
    'feature_fraction': 0.9,
    'feature_fraction_seed': 1,
    'max_bin': 256,
    'num_rounds': 80,
    'metric' : 'auc'
}

lgbm_model = lgb.LGBMClassifier(**params)

lgbm_model.fit(X_train, y_train)

"""## Evaluasi

### XGBoost
"""

y_pred_xgb = xgb_model.predict_proba(X_test)[::,1]

fpr, tpr, thresholds = roc_curve(y_test, y_pred_xgb)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Calculate the Youden's J statistic
youdenJ = tpr - fpr

# Find the optimal threshold
index = np.argmax(youdenJ)
thresholdOpt = round(thresholds[index], ndigits = 4)
youdenJOpt = round(youdenJ[index], ndigits = 4)
fprOpt = round(fpr[index], ndigits = 4)
tprOpt = round(tpr[index], ndigits = 4)
print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))
print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))

y_pred_convert = y_pred_xgb.copy()

for i in range(0, len(y_pred_convert)):
  if y_pred_convert[i] > thresholdOpt:
    y_pred_convert[i] = 1
  else:
    y_pred_convert[i] = 0

"""#### Hasil Evaluasi XGBoost"""

print("Accuracy XGBoost: ", accuracy_score(y_test, y_pred_convert))
print("Precision XGBoost: ", precision_score(y_test, y_pred_convert, average='macro'))
print("Recall XGBoost: ",recall_score(y_test, y_pred_convert, average='macro'))

score = roc_auc_score(y_test, y_pred_convert)

print(f"ROC AUC XGBoost: {score}")

f1_rf = f1_score(y_test, y_pred_convert)
print(f"F1 Score XGBoost: {f1_rf}")

# Confusion Matrix Random Forest
print("Cofusion Matrix XGBoost: \n", confusion_matrix(y_test, y_pred_convert))

"""### LightGBM"""

y_pred_lgbm = lgbm_model.predict_proba(X_test)[::,1]

fpr, tpr, thresholds = roc_curve(y_test, y_pred_lgbm)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Calculate the Youden's J statistic
youdenJ = tpr - fpr

# Find the optimal threshold
index = np.argmax(youdenJ)
thresholdOpt = round(thresholds[index], ndigits = 4)
youdenJOpt = round(youdenJ[index], ndigits = 4)
fprOpt = round(fpr[index], ndigits = 4)
tprOpt = round(tpr[index], ndigits = 4)
print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))
print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))

y_pred_convert = y_pred_lgbm.copy()

for i in range(0, len(y_pred_convert)):
  if y_pred_convert[i] > thresholdOpt:
    y_pred_convert[i] = 1
  else:
    y_pred_convert[i] = 0

"""#### Hasil Evaluasi LightGBM"""

print("Accuracy LightGBM: ", accuracy_score(y_test, y_pred_convert))
print("Precision LightGBM: ", precision_score(y_test, y_pred_convert, average='macro'))
print("Recall LightGBM: ",recall_score(y_test, y_pred_convert, average='macro'))

score = roc_auc_score(y_test, y_pred_convert)

print(f"ROC AUC LightGBM: {score}")

f1_rf = f1_score(y_test, y_pred_convert)
print(f"F1 Score LightGBM: {f1_rf}")

# Confusion Matrix Random Forest
print("Cofusion Matrix LightGBM: \n", confusion_matrix(y_test, y_pred_convert))